{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from os import mkdir\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from os import rename\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EI_true.zip ...\n",
      "Download Completed.\n",
      "Downloading IE_true.zip ...\n",
      "Download Completed.\n",
      "Downloading EI_false_1.zip ...\n",
      "Download Completed.\n",
      "Downloading EI_false_2.zip ...\n",
      "Download Completed.\n",
      "Downloading EI_false_3.zip ...\n",
      "Download Completed.\n",
      "Downloading IE_false_1.zip ...\n",
      "Download Completed.\n",
      "Downloading IE_false_2.zip ...\n",
      "Download Completed.\n",
      "Downloading IE_false_3.zip ...\n",
      "Download Completed.\n",
      "Downloading IE_false_4.zip ...\n",
      "Download Completed.\n",
      "All Downloads Completed!\n"
     ]
    }
   ],
   "source": [
    "# Create directory if it does not exists\n",
    "try:\n",
    "    mkdir('data')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Files to Download\n",
    "files = [\n",
    "    'EI_true.zip',\n",
    "    'IE_true.zip',\n",
    "    'EI_false_1.zip',\n",
    "    'EI_false_2.zip',\n",
    "    'EI_false_3.zip',\n",
    "    'IE_false_1.zip',\n",
    "    'IE_false_2.zip',\n",
    "    'IE_false_3.zip',\n",
    "    'IE_false_4.zip',\n",
    "]\n",
    "\n",
    "# Downloading and saving the files\n",
    "for file_name in files:\n",
    "    print(f'Downloading {file_name} ...')\n",
    "    with open(f'data/{file_name}', \"wb\") as file:\n",
    "        response = get(f'https://web.archive.org/web/20070731082332/http://www.sci.unisannio.it/docenti/rampone/{file_name}')\n",
    "        file.write(response.content)\n",
    "        print(f'Download Completed.')\n",
    "        time.sleep(10)\n",
    "print(f'All Downloads Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Compressed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EI_true.zip ...\n",
      "Extract Completed.\n",
      "Extracting IE_true.zip ...\n",
      "Extract Completed.\n",
      "Extracting EI_false_1.zip ...\n",
      "Extract Completed.\n",
      "Extracting EI_false_2.zip ...\n",
      "Extract Completed.\n",
      "Extracting EI_false_3.zip ...\n",
      "Extract Completed.\n",
      "Extracting IE_false_1.zip ...\n",
      "Extract Completed.\n",
      "Extracting IE_false_2.zip ...\n",
      "Extract Completed.\n",
      "Extracting IE_false_3.zip ...\n",
      "Extract Completed.\n",
      "Extracting IE_false_4.zip ...\n",
      "Extract Completed.\n",
      "All Files are Extracted!\n"
     ]
    }
   ],
   "source": [
    "for zip_file in files:\n",
    "    print(f'Extracting {zip_file} ...')\n",
    "    with zipfile.ZipFile(f'data/{zip_file}', 'r') as zip_ref:\n",
    "        dir_name = zip_file.split('.')[0]\n",
    "        zip_ref.extractall(f'data/{dir_name}')\n",
    "        print(f'Extract Completed.')\n",
    "print(f'All Files are Extracted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Files\n",
    "\n",
    "Marking the necessary file with sequence inromation. The necessary information is in `.seq` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'EI_false.002',\n",
       "  'file_location': 'data/EI_false_2/EI_false.seq.002',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': False},\n",
       " {'file_name': 'EI_false.001',\n",
       "  'file_location': 'data/EI_false_1/EI_false.seq.001',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': False},\n",
       " {'file_name': 'IE_true',\n",
       "  'file_location': 'data/IE_true/IE_true.seq',\n",
       "  'is_true': True,\n",
       "  'is_acceptor': True},\n",
       " {'file_name': 'IE_false.003',\n",
       "  'file_location': 'data/IE_false_3/IE_false.seq.003',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': True},\n",
       " {'file_name': 'EI_true',\n",
       "  'file_location': 'data/EI_true/EI_true.seq',\n",
       "  'is_true': True,\n",
       "  'is_acceptor': False},\n",
       " {'file_name': 'IE_false.004',\n",
       "  'file_location': 'data/IE_false_4/IE_false.seq.004',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': True},\n",
       " {'file_name': 'IE_false.001',\n",
       "  'file_location': 'data/IE_false_1/IE_false.seq.001',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': True},\n",
       " {'file_name': 'EI_false.003',\n",
       "  'file_location': 'data/EI_false_3/EI_false.seq.003',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': False},\n",
       " {'file_name': 'IE_false.002',\n",
       "  'file_location': 'data/IE_false_2/IE_false.seq.002',\n",
       "  'is_true': False,\n",
       "  'is_acceptor': True}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating File Information Objects\n",
    "data_files = []\n",
    "for root, dirs, files in os.walk('data/'):\n",
    "    for file in files:\n",
    "        if re.search('\\.seq.?\\d*$', file):\n",
    "            is_acceptor = bool(re.search('IE', file))\n",
    "            is_true = bool(re.search('true', file))\n",
    "            data_files.append({\n",
    "                'file_name': file.replace('.seq',''),\n",
    "                'file_location': os.path.join(root, file),\n",
    "                'is_true': is_true,\n",
    "                'is_acceptor': is_acceptor\n",
    "            })\n",
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Files\n",
    "\n",
    "Parsing the information within the files. This step will take a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing File EI_false.002 ...\n",
      "90430 datapoints.\n",
      "Parsing File EI_false.001 ...\n",
      "90921 datapoints.\n",
      "Parsing File IE_true ...\n",
      "2880 datapoints.\n",
      "Parsing File IE_false.003 ...\n",
      "90623 datapoints.\n",
      "Parsing File EI_true ...\n",
      "2796 datapoints.\n",
      "Parsing File IE_false.004 ...\n",
      "57481 datapoints.\n",
      "Parsing File IE_false.001 ...\n",
      "90915 datapoints.\n",
      "Parsing File EI_false.003 ...\n",
      "90575 datapoints.\n",
      "Parsing File IE_false.002 ...\n",
      "90340 datapoints.\n"
     ]
    }
   ],
   "source": [
    "# Converting Files to Numpy Arrays and saving .npz\n",
    "\n",
    "# Using reqular expression to extract the RNA sequences.\n",
    "detector = re.compile('[ACGT]{140}')\n",
    "\n",
    "# Categorizing the bases\n",
    "nucleotides = {\n",
    "    'A': 0,\n",
    "    'C': 1,\n",
    "    'G': 2,\n",
    "    'T': 3,\n",
    "}\n",
    "def convert_nucleotides(sequence):\n",
    "    return [nucleotides[nucleotide] for nucleotide in sequence]\n",
    "\n",
    "# Encoding Labels\n",
    "def get_label(file_obj):\n",
    "    \"\"\"\n",
    "    0: None\n",
    "    1: Acceptor\n",
    "    2: Donor\n",
    "    \"\"\"\n",
    "    if not file_obj['is_true']:\n",
    "        return 0\n",
    "    if file_obj['is_acceptor']:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "# Going through each candidate file\n",
    "for file_obj in data_files:\n",
    "    file_name = file_obj['file_name']\n",
    "    # Skip if file is aleady processed\n",
    "    if os.path.isfile(f'data/{file_name}.npz'):\n",
    "        print(f'{file_name} exists ...')\n",
    "        continue\n",
    "        \n",
    "    data_count = 0\n",
    "    # Read the seq file\n",
    "    with open(file_obj['file_location'], 'r') as f:\n",
    "        data_X = np.empty_like([])\n",
    "        data_y = np.empty_like([])\n",
    "        print(f'Parsing File {file_name} ...')\n",
    "        for line in f:\n",
    "            # Extracting info using reqular expressions\n",
    "            result = detector.findall(line)\n",
    "            if result:\n",
    "                data_count+=1\n",
    "                data_X = np.append(data_X, convert_nucleotides(result[0]))\n",
    "                data_y = np.append(data_y, get_label(file_obj))\n",
    "                print(data_count, end='\\r')\n",
    "        # Saving the data as compressed .npz file\n",
    "        np.savez_compressed(f'data/{file_name}.npz', X=data_X, y=data_y)\n",
    "        print(f'{data_count} datapoints.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping the data\n",
    "\n",
    "The data should be in the shape of `(<number_of_data>, 140)` and labels like `(<number_of_data>, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and reshaping files\n",
    "for file_obj in data_files:\n",
    "    file_name = file_obj['file_name']\n",
    "    file_location = f'data/{file_name}.npz'\n",
    "    data = np.load(file_location)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    X = X.reshape(-1, 140)\n",
    "    y = y.reshape(-1, 1)\n",
    "    np.savez_compressed(f'data/{file_name}.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and Encoding\n",
    "for file_obj in data_files:\n",
    "    file_name = file_obj['file_name']\n",
    "    file_location = f'data/{file_name}.npz'\n",
    "    # Loading Files\n",
    "    data = np.load(file_location)\n",
    "    \n",
    "    X = data['X']\n",
    "    X_encoded = np.zeros(shape=(*X.shape, 4))\n",
    "    # Encoding\n",
    "    for r in range(X.shape[0]):\n",
    "        for c in range(X.shape[1]):\n",
    "            X_encoded[r, c, int(X[r, c])] = 1\n",
    "    y = data['y']\n",
    "    y_encoded = np.zeros(shape=(y.shape[0], 3))\n",
    "    for r in range(y.shape[0]):\n",
    "        y_encoded[r, int(y[r])] = 1\n",
    "    # Saving Files\n",
    "    np.savez_compressed(f'data/encoded_{file_name}.npz', X=X_encoded, y=y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Information For Control\n",
    "\n",
    "The shape of the data shoule be `(<number_of_data>, 140, 4)`.\n",
    "\n",
    "The shape of the lables should be `(<number_of_data>, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/encoded_EI_false.002.npz (90430, 140, 4) (90430, 3)\n",
      "data/encoded_EI_false.001.npz (90921, 140, 4) (90921, 3)\n",
      "data/encoded_IE_true.npz (2880, 140, 4) (2880, 3)\n",
      "data/encoded_IE_false.003.npz (90623, 140, 4) (90623, 3)\n",
      "data/encoded_EI_true.npz (2796, 140, 4) (2796, 3)\n",
      "data/encoded_IE_false.004.npz (57481, 140, 4) (57481, 3)\n",
      "data/encoded_IE_false.001.npz (90915, 140, 4) (90915, 3)\n",
      "data/encoded_EI_false.003.npz (90575, 140, 4) (90575, 3)\n",
      "data/encoded_IE_false.002.npz (90340, 140, 4) (90340, 3)\n"
     ]
    }
   ],
   "source": [
    "# Displaying information\n",
    "for file_obj in data_files:\n",
    "    file_name = file_obj['file_name']\n",
    "    file_location = f'data/encoded_{file_name}.npz'\n",
    "    data = np.load(file_location)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    \n",
    "    print(file_location, X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Files\n",
    "\n",
    "`false` data files are separeted and need to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combining IE_false \n",
    "IE_false_X = np.empty(shape=(0, 140, 4))\n",
    "for file_obj in data_files:\n",
    "    if not file_obj['file_name'].startswith('IE_false'):\n",
    "        continue\n",
    "    file_name = file_obj['file_name']\n",
    "    file_location = f'data/encoded_{file_name}.npz'\n",
    "    data = np.load(file_location)\n",
    "    IE_false_X = np.append(IE_false_X, data['X'], axis=0)\n",
    "IE_false_y = np.zeros(shape=(IE_false_X.shape[0], 3))\n",
    "IE_false_y[:, 0] = 1\n",
    "np.savez_compressed('data/encoded_IE_false.npz', X=IE_false_X, y=IE_false_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining IE_false \n",
    "IE_false_X = np.empty(shape=(0, 140))\n",
    "for file in ['IE_false.004.npz', 'IE_false.003.npz', 'IE_false.002.npz', 'IE_false.001.npz']:\n",
    "    file_location = f'data/{file}'\n",
    "    data = np.load(file_location)\n",
    "    IE_false_X = np.append(IE_false_X, data['X'], axis=0)\n",
    "IE_false_y = np.zeros(shape=(IE_false_X.shape[0]))\n",
    "np.savez_compressed('data/IE_false.npz', X=IE_false_X, y=IE_false_y)\n",
    "print(IE_false_X.shape)\n",
    "print(IE_false_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining EI_false \n",
    "EI_false_X = np.empty(shape=(0, 140, 4))\n",
    "for file_obj in data_files:\n",
    "    if not file_obj['file_name'].startswith('EI_false'):\n",
    "        continue\n",
    "    file_name = file_obj['file_name']\n",
    "    file_location = f'data/encoded_{file_name}.npz'\n",
    "    data = np.load(file_location)\n",
    "    EI_false_X = np.append(EI_false_X, data['X'], axis=0)\n",
    "EI_false_y = np.zeros(shape=(EI_false_X.shape[0], 3))\n",
    "EI_false_y[:, 0] = 1\n",
    "np.savez_compressed('data/encoded_EI_false.npz', X=EI_false_X, y=EI_false_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining EI_false \n",
    "EI_false_X = np.empty(shape=(0, 140))\n",
    "for file in ['EI_false.003.npz', 'EI_false.002.npz', 'EI_false.001.npz']:\n",
    "    file_location = f'data/{file}'\n",
    "    data = np.load(file_location)\n",
    "    EI_false_X = np.append(EI_false_X, data['X'], axis=0)\n",
    "EI_false_y = np.zeros(shape=(EI_false_X.shape[0]))\n",
    "np.savez_compressed('data/EI_false.npz', X=EI_false_X, y=EI_false_y)\n",
    "print(EI_false_X.shape)\n",
    "print(EI_false_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329359, 140, 4)\n",
      "(329359, 3)\n"
     ]
    }
   ],
   "source": [
    "# Displaying information\n",
    "data = np.load('data/encoded_IE_false.npz')\n",
    "print(data['X'].shape)\n",
    "print(data['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271926, 140, 4)\n",
      "(271926, 3)\n"
     ]
    }
   ],
   "source": [
    "# Displaying information\n",
    "data = np.load('data/encoded_EI_false.npz')\n",
    "print(data['X'].shape)\n",
    "print(data['y'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all False Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining falses\n",
    "false_X = np.empty(shape=(0, 140, 4))\n",
    "for file in ['data/encoded_IE_false.npz', 'data/encoded_EI_false.npz']:\n",
    "    data = np.load(file)\n",
    "    false_X = np.append(false_X, data['X'], axis=0)\n",
    "false_y = np.zeros(shape=(false_X.shape[0], 3))\n",
    "false_y[:, 0] = 1\n",
    "np.savez_compressed('data/encoded_false.npz', X=false_X, y=false_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying information\n",
    "data = np.load('data/encoded_false.npz')\n",
    "print(data['X'].shape)\n",
    "print(data['y'].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling\n",
    "\n",
    "This dataset is considered unbalanced, since on average we have 200 times more `false` data than `donor` or `acceptor` data.\n",
    "\n",
    "In order to not lose useful information, I decided to balance the dataset by upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of category 0 (false) information\n",
    "false_data = np.load('data/encoded_false.npz')\n",
    "false_length = false_data['X'].shape[0]\n",
    "print(false_length)\n",
    "\n",
    "# Repeating category 1 informating to match categoty 0 in numbers\n",
    "EI_true_data = np.load('data/encoded_EI_true.npz')\n",
    "X = EI_true_data['X']\n",
    "y = EI_true_data['y']\n",
    "X_length = X.shape[0]\n",
    "multiple = false_length//X_length\n",
    "if multiple > 1:\n",
    "    X = np.repeat(X, multiple, axis=0)\n",
    "    y = np.repeat(y, multiple, axis=0)\n",
    "    np.savez_compressed('data/encoded_EI_true_upsampled.npz', X=X, y=y)\n",
    "print(X.shape[0], y.shape[0])\n",
    "\n",
    "# Repeating category 2 informating to match categoty 0 in numbers\n",
    "IE_true_data = np.load('data/encoded_IE_true.npz')\n",
    "X = IE_true_data['X']\n",
    "y = IE_true_data['y']\n",
    "X_length = X.shape[0]\n",
    "multiple = false_length//X_length\n",
    "if multiple > 1:\n",
    "    X = np.repeat(X, multiple, axis=0)\n",
    "    y = np.repeat(y, multiple, axis=0)\n",
    "    np.savez_compressed('data/encoded_IE_true_upsampled.npz', X=X, y=y)\n",
    "print(X.shape[0], y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the data\n",
    "imported_files = [\n",
    "    'data/encoded_EI_true_upsampled.npz',\n",
    "    'data/encoded_IE_true_upsampled.npz',\n",
    "    'data/encoded_false.npz',\n",
    "]\n",
    "\n",
    "for file in imported_files:\n",
    "    data = np.load(file)\n",
    "    print(data['X'].shape)\n",
    "    print(data['y'].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining All Data for Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining All\n",
    "X = np.empty(shape=(0, 140, 4))\n",
    "y = np.empty(shape=(0, 3))\n",
    "for file in imported_files:\n",
    "    data = np.load(file)\n",
    "    X = np.append(X, data['X'], axis=0)\n",
    "    y = np.append(y, data['y'], axis=0)\n",
    "np.savez_compressed('combined_data.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valdiation\n",
    "\n",
    "data = np.load('combined_data.npz')\n",
    "print(data['X'].shape)\n",
    "print(data['y'].shape, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the Temp Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('data')\n",
    "    print('\"data\" directory is removed!')\n",
    "except Exception:\n",
    "    print('\"data\" directory does not exist!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
